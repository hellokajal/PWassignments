{
 "cells": [
  {
   "cell_type": "raw",
   "id": "d570c214-2be9-4455-8994-77b64b179e44",
   "metadata": {},
   "source": [
    "1. Discuss the scenarios where multithreading is preferable to multiprocessing and scenarios where \n",
    "multiprocessing is a better choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92685e1-c16d-42c5-b3c2-42bddcfa5a1d",
   "metadata": {},
   "source": [
    "### Multithreading"
   ]
  },
  {
   "cell_type": "raw",
   "id": "048ea919-117d-488a-a505-3752d50d38e9",
   "metadata": {},
   "source": [
    "1. I/O-Bound Tasks:\n",
    "\n",
    "Scenario: Tasks involving significant waiting times, such as reading from or writing to files, network operations, or database queries.\n",
    "Reason: Threads can efficiently handle multiple I/O operations concurrently because while one thread waits for I/O, others can continue processing. The Global Interpreter Lock (GIL) in Python, for instance, can be less of a hindrance in I/O-bound scenarios.\n",
    "\n",
    "2. Shared State:\n",
    "\n",
    "Scenario: Tasks that require frequent communication or shared state between threads.\n",
    "Reason: Threads within the same process share memory space, making it easier and more efficient to share data. This can reduce the overhead associated with inter-process communication (IPC) found in multiprocessing.\n",
    "\n",
    "3. Lightweight Context Switching:\n",
    "\n",
    "Scenario: Situations where the overhead of context switching between tasks needs to be minimal.\n",
    "Reason: Switching between threads is generally cheaper in terms of performance compared to switching between processes, which involve more overhead due to the need for separate memory spaces.\n",
    "\n",
    "4. Low-Level System Tasks:\n",
    "\n",
    "Scenario: When tasks are closely related to system-level operations, such as managing system resources or performing background tasks.\n",
    "Reason: Multithreading can be more suitable for fine-grained control and low-level operations, given its more lightweight nature compared to processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18c3e42-e691-479c-b211-527c676c7f28",
   "metadata": {},
   "source": [
    "### Multiprocessing"
   ]
  },
  {
   "cell_type": "raw",
   "id": "156d6d43-e253-45aa-af57-7a35e46c40b1",
   "metadata": {},
   "source": [
    "1. CPU-Bound Tasks:\n",
    "\n",
    "Scenario: Tasks that require significant computational power, such as complex calculations, data processing, or simulations.\n",
    "Reason: Multiprocessing can bypass the limitations of the Global Interpreter Lock (GIL) in Python by running each process in its own memory space, allowing true parallel execution on multiple CPU cores.\n",
    "\n",
    "2. Isolation and Stability:\n",
    "\n",
    "Scenario: Situations where tasks need to be isolated to prevent crashes or memory leaks from affecting other tasks.\n",
    "Reason: Processes run in separate memory spaces, so a crash in one process does not impact others. This isolation can be crucial for stability in complex applications.\n",
    "\n",
    "3. Heavy Resource Management:\n",
    "\n",
    "Scenario: Tasks that involve managing heavy resources or running resource-intensive applications.\n",
    "Reason: Multiprocessing can better handle tasks that need separate memory space and resource management, avoiding the issues that might arise from shared memory in multithreading.\n",
    "\n",
    "4. Complex Problem Decomposition:\n",
    "\n",
    "Scenario: Decomposing a large, complex problem into independent, parallel tasks that do not need frequent communication.\n",
    "Reason: Processes can operate independently with less overhead for synchronization, as each process has its own memory space. This setup is ideal for tasks that can be parallelized without tight interdependencies."
   ]
  },
  {
   "cell_type": "raw",
   "id": "69aea6c3-1e5a-4d5e-bfa2-d2014b50ed45",
   "metadata": {},
   "source": [
    "2. Describe what a process pool is and how it helps in managing multiple processes efficiently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091ed225-9968-4b46-ab33-95f35d587ad7",
   "metadata": {},
   "source": [
    "### What a Process Pool?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b242802f-9ab2-4965-8a45-e9d2115554f7",
   "metadata": {},
   "source": [
    "A process pool is a collection of pre-instantiated, idle processes that are managed by a pool manager. It is designed to handle multiple tasks concurrently by distributing them among the available processes in the pool. This approach allows for efficient management of processes, especially in scenarios involving parallel execution of tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6904b386-70d0-41f6-87f5-4626188bf7fb",
   "metadata": {},
   "source": [
    "### Key Concepts of a Process Pool:\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d846ae1c-5fa3-4d76-a3a5-dc740f00d581",
   "metadata": {},
   "source": [
    "1. Process Pool Management: A pool manager oversees the lifecycle of the processes within the pool. It handles the creation, scheduling, and termination of processes as needed.\n",
    "\n",
    "2. Task Distribution: Tasks are submitted to the pool manager, which assigns them to the available processes in the pool. This avoids the overhead of repeatedly creating and destroying processes for each task.\n",
    "\n",
    "3. Concurrency: Multiple tasks can be processed at the same time, leveraging parallelism to improve performance and reduce the total time required for execution.\n",
    "\n",
    "4. Resource Optimization: By reusing a fixed number of processes, a process pool helps optimize resource usage, reducing the cost and overhead associated with frequent process creation and destruction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3967708-279b-4b57-964b-d82ea3dabeec",
   "metadata": {},
   "source": [
    "### Benefits of Using a Process Pool:"
   ]
  },
  {
   "cell_type": "raw",
   "id": "95172588-2c7d-43e0-90db-092b4d1c0cb0",
   "metadata": {},
   "source": [
    "1. Reduced Overhead: Eliminates the need to create and destroy processes frequently. Once processes are created and idle, they can be reused for multiple tasks, reducing the overhead associated with process management.\n",
    "\n",
    "2. Improved Performance: By executing tasks concurrently, a process pool can significantly reduce the total execution time, especially for tasks that are CPU-bound or computationally intensive.\n",
    "\n",
    "3. Efficient Resource Use: Ensures that system resources (like CPU and memory) are utilized more effectively by managing a limited number of processes rather than creating new ones for each task.\n",
    "\n",
    "4. Scalability: Allows for scalable execution of tasks. The pool size can be adjusted based on the workload and system capabilities."
   ]
  },
  {
   "cell_type": "raw",
   "id": "0349a04b-7c72-4996-b3ed-f91b0747b8c8",
   "metadata": {},
   "source": [
    "3. Explain what multiprocessing is and why it is used in Python programs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6291ba97-6fe8-49bb-882d-6f393c851579",
   "metadata": {},
   "source": [
    "### What is Multiprocessing?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0db62d91-12e3-4bc4-a513-21e3de4c6596",
   "metadata": {},
   "source": [
    "Multiprocessing refers to the ability of a computer to run multiple processes in parallel. Each process runs independently, with its own memory space, and can perform computations simultaneously. Unlike threads, which share the same memory space, processes are isolated from each other, which can lead to more effective parallel execution for CPU-intensive tasks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "138516be-ba6f-422a-b61c-c27295818ab8",
   "metadata": {},
   "source": [
    "### Why is Multiprocessing Used in Python Programs?"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aeea612c-2da0-4d3b-9c8f-133cc5f6cc65",
   "metadata": {},
   "source": [
    "1. Global Interpreter Lock (GIL) Limitation: Python's default implementation, CPython, has a Global Interpreter Lock (GIL) that prevents multiple native threads from executing Python bytecodes at once. This can be a bottleneck for CPU-bound tasks. Multiprocessing bypasses the GIL by using separate processes, each with its own Python interpreter and memory space, thus enabling true parallelism.\n",
    "\n",
    "2. Parallel Processing: Multiprocessing allows programs to perform multiple tasks simultaneously, which can lead to significant performance improvements, particularly for CPU-bound tasks like data processing, computations, or simulations. It helps utilize multiple CPU cores effectively.\n",
    "\n",
    "3. Isolation and Stability: Each process in a multiprocessing setup runs in its own memory space. This isolation prevents issues like data corruption that can occur with threads sharing memory. If one process crashes, it does not affect the others, leading to more stable programs.\n",
    "\n",
    "4. Improved Performance for Certain Tasks: For tasks that can be divided into independent chunks (e.g., processing items in a list or handling multiple requests), multiprocessing can significantly reduce execution time by parallelizing the work."
   ]
  },
  {
   "cell_type": "raw",
   "id": "960b36bb-8149-464e-b385-2a7fd927f49e",
   "metadata": {},
   "source": [
    "4. Write a Python program using multithreading where one thread adds numbers to a list, and another \n",
    "thread removes numbers from the list. Implement a mechanism to avoid race conditions using \n",
    "threading.Lock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf86adf1-d467-4b2e-9efd-87419fcbfa6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 48: [48]\n",
      "Removed 48: []\n",
      "Added 44: [44]\n",
      "Removed 44: []\n",
      "Added 17: [17]\n",
      "Removed 17: []\n",
      "Added 26: [26]\n",
      "Removed 26: []\n",
      "Added 20: [20]\n",
      "Removed 20: []\n",
      "Added 53: [53]\n",
      "Removed 53: []\n",
      "Added 40: [40]\n",
      "Added 70: [40, 70]\n",
      "Removed 40: [70]\n",
      "Removed 70: []\n",
      "Added 36: [36]\n",
      "Added 97: [36, 97]\n",
      "Final shared list: [36, 97]\n"
     ]
    }
   ],
   "source": [
    "import threading\n",
    "import time\n",
    "import random\n",
    "\n",
    "# Shared resource\n",
    "shared_list = []\n",
    "lock = threading.Lock()\n",
    "\n",
    "# Function to add numbers to the list\n",
    "def add_numbers():\n",
    "    global shared_list\n",
    "    for _ in range(10):\n",
    "        # Acquire the lock before modifying the list\n",
    "        with lock:\n",
    "            num = random.randint(1, 100)\n",
    "            shared_list.append(num)\n",
    "            print(f\"Added {num}: {shared_list}\")\n",
    "        # Simulate some delay\n",
    "        time.sleep(random.uniform(0.1, 0.5))\n",
    "\n",
    "# Function to remove numbers from the list\n",
    "def remove_numbers():\n",
    "    global shared_list\n",
    "    for _ in range(10):\n",
    "        # Acquire the lock before modifying the list\n",
    "        with lock:\n",
    "            if shared_list:\n",
    "                num = shared_list.pop(0)\n",
    "                print(f\"Removed {num}: {shared_list}\")\n",
    "        # Simulate some delay\n",
    "        time.sleep(random.uniform(0.1, 0.5))\n",
    "\n",
    "# Create threads\n",
    "adder_thread = threading.Thread(target=add_numbers)\n",
    "remover_thread = threading.Thread(target=remove_numbers)\n",
    "\n",
    "# Start threads\n",
    "adder_thread.start()\n",
    "remover_thread.start()\n",
    "\n",
    "# Wait for threads to finish\n",
    "adder_thread.join()\n",
    "remover_thread.join()\n",
    "\n",
    "print(\"Final shared list:\", shared_list)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4cba979c-1e5f-4f21-8870-4bd63c09919e",
   "metadata": {},
   "source": [
    "5. Describe the methods and tools available in Python for safely sharing data between threads and \n",
    "processes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53a9de7-3532-416d-b2ec-9dd85dee46d4",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 1. Thread-Based Concurrency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c5e4ed-c53e-49ca-bf2b-69708802569c",
   "metadata": {},
   "source": [
    "#### a. Threading Locks"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3cce7bae-f0b1-410a-9585-ddb64cd2f5ca",
   "metadata": {},
   "source": [
    "threading.Lock: A basic synchronization primitive that ensures that only one thread can access a particular section of code or resource at a time. It’s used to prevent race conditions.\n",
    "\n",
    "Syntax :\n",
    "\n",
    "import threading\n",
    "\n",
    "lock = threading.Lock()\n",
    "\n",
    "with lock:\n",
    "    # Critical section of code\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "05184c9e-91b1-4d45-a582-281d48567297",
   "metadata": {},
   "source": [
    "threading.RLock: A reentrant lock, which allows a thread to acquire the same lock multiple times without causing a deadlock. Useful when a thread needs to acquire the lock recursively.\n",
    "\n",
    "Syntax:\n",
    "\n",
    "import threading\n",
    "\n",
    "rlock = threading.RLock()\n",
    "\n",
    "with rlock:\n",
    "    # Critical section of code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71516975-d538-40ec-b075-0d8d467d3b45",
   "metadata": {},
   "source": [
    "#### b. Condition Variables"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1fc65868-3478-4d3d-9ee1-169c3df08ff6",
   "metadata": {},
   "source": [
    "threading.Condition: Allows threads to wait for some condition to be met. It can be used for more complex synchronization scenarios where threads need to wait for a particular state.\n",
    "\n",
    "\n",
    "Syntax:\n",
    "\n",
    "\n",
    "import threading\n",
    "\n",
    "condition = threading.Condition()\n",
    "\n",
    "with condition:\n",
    "    condition.wait()  # Wait until notified\n",
    "    # Do work\n",
    "    condition.notify()  # Notify waiting threads"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48a7bbd-4b3c-48d3-90f3-cb753dcfd94c",
   "metadata": {},
   "source": [
    "#### c. Semaphores"
   ]
  },
  {
   "cell_type": "raw",
   "id": "489beee1-7d2a-40a7-bd4c-064588ec4f2d",
   "metadata": {},
   "source": [
    "threading.Semaphore: Limits the number of threads that can access a resource concurrently. Useful for managing access to a pool of resources.\n",
    "\n",
    "\n",
    "Syntax:\n",
    "\n",
    "\n",
    "import threading\n",
    "\n",
    "semaphore = threading.Semaphore(2)  # Allow up to 2 threads\n",
    "\n",
    "with semaphore:\n",
    "    # Critical section of code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad38624-a478-4ca4-a665-eaf3cff6566f",
   "metadata": {},
   "source": [
    "#### d. Queues"
   ]
  },
  {
   "cell_type": "raw",
   "id": "04de35d2-880f-44ec-8cee-ae36d4dfe76c",
   "metadata": {},
   "source": [
    "queue.Queue: A thread-safe FIFO queue that can be used to pass data between threads. It supports safe operations like put() and get(), which are thread-safe.\n",
    "\n",
    "\n",
    "Syntax:\n",
    "\n",
    "import queue\n",
    "\n",
    "q = queue.Queue()\n",
    "\n",
    "q.put(item)  # Add item to the queue\n",
    "item = q.get()  # Retrieve item from the queue"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48227ad1-e45a-4a1e-b323-800dc85587a0",
   "metadata": {},
   "source": [
    "## 2. Process-Based Concurrency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59feb0d2-e0ba-4601-9521-76494d387d08",
   "metadata": {},
   "source": [
    "#### a. Multiprocessing Locks"
   ]
  },
  {
   "cell_type": "raw",
   "id": "809487aa-60c8-4cc4-abb5-bde7b9c574f8",
   "metadata": {},
   "source": [
    "multiprocessing.Lock: Similar to threading.Lock, but for process-based synchronization. Ensures that only one process can execute a critical section at a time.\n",
    "\n",
    "\n",
    "Syntax:\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "lock = multiprocessing.Lock()\n",
    "\n",
    "with lock:\n",
    "    # Critical section of code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adc6699-69fc-4a0b-9b8e-0b18c7577159",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### b. Event Objects"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb5d5802-ce35-4ab8-9ab0-bd4bdac3b901",
   "metadata": {},
   "source": [
    "multiprocessing.Event: Allows processes to synchronize by signaling between them. One process can set the event, and others can wait for it.\n",
    "\n",
    "\n",
    "Syntax:\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "event = multiprocessing.Event()\n",
    "\n",
    "# Set the event\n",
    "event.set()\n",
    "\n",
    "# Wait for the event to be set\n",
    "event.wait()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47286ddd-4155-40a2-ab9c-938b13041e9b",
   "metadata": {},
   "source": [
    "#### c. Condition Objects"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e9acbbaa-6486-4ff1-b033-a6d813e5c857",
   "metadata": {},
   "source": [
    "multiprocessing.Condition: Similar to threading.Condition, but for process synchronization. Used for waiting for and notifying other processes.\n",
    "\n",
    "Syntax:\n",
    "\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "condition = multiprocessing.Condition()\n",
    "\n",
    "with condition:\n",
    "    condition.wait()  # Wait until notified\n",
    "    # Do work\n",
    "    condition.notify()  # Notify waiting processes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1a5510-3143-41df-bd2a-8dab0e629fc5",
   "metadata": {},
   "source": [
    "#### d. Semaphores"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2422e6c7-935d-4a94-b8f4-0b45985b772a",
   "metadata": {},
   "source": [
    "multiprocessing.Semaphore: Similar to threading.Semaphore, but for processes. Limits the number of processes that can access a resource concurrently.\n",
    "\n",
    "Syntax:\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "semaphore = multiprocessing.Semaphore(2)  # Allow up to 2 processes\n",
    "\n",
    "with semaphore:\n",
    "    # Critical section of code\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a992c7b5-bed5-4d71-8deb-3afafd07fbdd",
   "metadata": {},
   "source": [
    "#### e. Queues"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4f049f1a-d5a5-4916-881b-ba072231de54",
   "metadata": {},
   "source": [
    "multiprocessing.Queue: A process-safe FIFO queue for communication between processes. Like queue.Queue, but designed for inter-process communication.\n",
    "\n",
    "\n",
    "Syntax:\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "q = multiprocessing.Queue()\n",
    "\n",
    "q.put(item)  # Add item to the queue\n",
    "item = q.get()  # Retrieve item from the queue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c975a6c1-7e0e-4951-b972-5fdabb5bd203",
   "metadata": {},
   "source": [
    "#### f. Pipes"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8ff36f5b-06f7-4bca-b793-c903fa260b1b",
   "metadata": {},
   "source": [
    "multiprocessing.Pipe: Allows two-way communication between two processes. Pipes provide a way to send data between processes with a connection object.\n",
    "\n",
    "Syntax:\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "parent_conn, child_conn = multiprocessing.Pipe()\n",
    "\n",
    "# In parent process\n",
    "parent_conn.send(data)\n",
    "data = parent_conn.recv()\n",
    "\n",
    "# In child process\n",
    "data = child_conn.recv()\n",
    "child_conn.send(response)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "014c7687-dbe7-441f-bf27-7747a42f28be",
   "metadata": {},
   "source": [
    "6. Discuss why it’s crucial to handle exceptions in concurrent programs and the techniques available for \n",
    "doing so."
   ]
  },
  {
   "cell_type": "raw",
   "id": "0bb52aaf-bed6-4629-997a-912193799d93",
   "metadata": {},
   "source": [
    "Handling exceptions in concurrent programs is crucial because concurrent programs involve multiple threads or processes running simultaneously, which can introduce complexities that are not present in sequential programs. Here are the key reasons why handling exceptions in concurrent programs is essential:\n",
    "\n",
    "1. Ensuring Stability and Reliability\n",
    "Concurrent programs can fail in unpredictable ways due to race conditions, deadlocks, and other concurrency issues. If exceptions are not properly handled, they can cause the entire application to crash or lead to inconsistent states. Proper exception handling ensures that the program can recover gracefully and maintain stability.\n",
    "\n",
    "2. Preventing Resource Leaks\n",
    "Concurrent programs often involve the use of shared resources such as memory, files, or network connections. If an exception occurs and is not handled, resources may not be released properly, leading to resource leaks or deadlocks. Proper handling ensures that resources are cleaned up correctly.\n",
    "\n",
    "3. Providing Accurate Debugging Information\n",
    "Exceptions in concurrent programs can be harder to trace due to the interleaving of threads. Without proper handling, it might be difficult to determine the root cause of an issue. Handling exceptions correctly can provide more detailed error messages and context, making debugging easier.\n",
    "\n",
    "4. Maintaining Data Consistency\n",
    "When exceptions occur, especially in concurrent environments, there is a risk of leaving shared data in an inconsistent state. Handling exceptions properly can help ensure that data remains consistent and that any necessary rollbacks or compensations are performed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "549f725f-cde9-41e2-a3e6-3485c7e110e9",
   "metadata": {},
   "source": [
    "#### Techniques for Handling Exceptions in Concurrent Programs"
   ]
  },
  {
   "cell_type": "raw",
   "id": "44662ac1-0bf0-4baf-bb79-35ee64bdef10",
   "metadata": {},
   "source": [
    "1. Thread-local Exception Handling\n",
    "Each thread can handle its own exceptions using try-catch blocks within the thread's execution code. This ensures that exceptions are caught and managed at the thread level, preventing them from affecting other threads.\n",
    "\n",
    "2. Using Futures and Executors\n",
    "In languages like Java, the Future and ExecutorService classes provide a way to manage concurrent tasks and handle exceptions. When using Future, you can catch exceptions by calling the get method, which will rethrow any exception that occurred during task execution.\n",
    "\n",
    "3. Handling Exceptions in Callbacks\n",
    "When using asynchronous programming models, such as callbacks or promises, it’s important to handle exceptions within the callback functions. For instance, in JavaScript with promises.\n",
    "\n",
    "4. Using Synchronization Mechanisms\n",
    "Proper synchronization mechanisms, like locks or semaphores, can help manage access to shared resources and avoid exceptions related to race conditions. While this doesn't directly handle exceptions, it helps prevent situations that could lead to exceptions.\n",
    "\n",
    "5. Global Exception Handlers\n",
    "For some programming environments, you can set up global exception handlers that catch unhandled exceptions across threads or processes. For example, in Java, you can use Thread.setDefaultUncaughtExceptionHandler to handle uncaught exceptions in any thread.\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7d9f98ec-7456-4fcc-a03b-666dfee6e0bc",
   "metadata": {},
   "source": [
    "7. Create a program that uses a thread pool to calculate the factorial of numbers from 1 to 10 concurrently. \n",
    "Use concurrent.futures.ThreadPoolExecutor to manage the threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "36b7c642-4adb-4654-b299-74ea55993f2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Factorial of 1 is 1\n",
      "Factorial of 2 is 2\n",
      "Factorial of 3 is 6\n",
      "Factorial of 4 is 24\n",
      "Factorial of 5 is 120\n",
      "Factorial of 6 is 720\n",
      "Factorial of 7 is 5040\n",
      "Factorial of 8 is 40320\n",
      "Factorial of 9 is 362880\n",
      "Factorial of 10 is 3628800\n"
     ]
    }
   ],
   "source": [
    "import concurrent.futures\n",
    "import math\n",
    "\n",
    "def factorial(n):\n",
    "    \"\"\"Compute the factorial of a number.\"\"\"\n",
    "    return math.factorial(n)\n",
    "\n",
    "def main():\n",
    "    # Define the range of numbers for which we want to compute factorials\n",
    "    numbers = list(range(1, 11))\n",
    "    \n",
    "    # Create a ThreadPoolExecutor to manage the threads\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        # Map the factorial function to the list of numbers\n",
    "        results = executor.map(factorial, numbers)\n",
    "        \n",
    "        # Print the results\n",
    "        for number, result in zip(numbers, results):\n",
    "            print(f\"Factorial of {number} is {result}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4ed27e74-18d2-40f6-bd7d-782b94f129f5",
   "metadata": {},
   "source": [
    "8. Create a Python program that uses multiprocessing.Pool to compute the square of numbers from 1 to 10 in \n",
    "parallel. Measure the time taken to perform this computation using a pool of different sizes (e.g., 2, 4, 8 \n",
    "processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a856bc5-3e31-41bf-b461-288015e38623",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pool size: 2\n",
      "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
      "Time taken: 0.0466 seconds\n",
      "----------------------------------------\n",
      "Pool size: 4\n",
      "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
      "Time taken: 0.0750 seconds\n",
      "----------------------------------------\n",
      "Pool size: 8\n",
      "Results: [1, 4, 9, 16, 25, 36, 49, 64, 81, 100]\n",
      "Time taken: 0.1271 seconds\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "import time\n",
    "\n",
    "def square(n):\n",
    "    \"\"\"Compute the square of a number.\"\"\"\n",
    "    return n * n\n",
    "\n",
    "def measure_time(pool_size):\n",
    "    \"\"\"Measure the time taken to compute squares using a pool of the given size.\"\"\"\n",
    "    numbers = list(range(1, 11))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Create a Pool with the specified number of processes\n",
    "    with multiprocessing.Pool(pool_size) as pool:\n",
    "        results = pool.map(square, numbers)\n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Print results and time taken\n",
    "    print(f\"Pool size: {pool_size}\")\n",
    "    print(f\"Results: {results}\")\n",
    "    print(f\"Time taken: {end_time - start_time:.4f} seconds\")\n",
    "    print('-' * 40)\n",
    "\n",
    "def main():\n",
    "    # Test different pool sizes\n",
    "    pool_sizes = [2, 4, 8]\n",
    "    for size in pool_sizes:\n",
    "        measure_time(size)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
